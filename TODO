* Rename Categorical.from_strings (misleading name)

* Rename DesignMatrixColumnInfo
because it's very annoying to type
but what would be a better name?

* As a safety check for non-stateful transforms, we should always
evaluate each formula on just the first row of data alone, and make
sure the result matches what we got when evaluating it vectorized
(i.e., confirm f(x[0]) == f(x)[0], where f is our transform. However,
this is kind of tricky given that x might be pulled out of the
environment, the 'data' dict might have arbitrary objects,
etc. Hmm. Maybe intercept variable lookups and just munge those? This
is easy to do if someone's passing in a structured array or dataframe
and pulling all their data from it, or even if they use a dict with
well-behaved columns.

* More contrast tools
- Some sort of symbolic tools for user-defined contrasts -- take the
  comparisons that people want to compute in terms of linear
  combinations of level names, convert that to a matrix and do the
  pinv dance? We have the linear_contrast code already, but that's for
  describing 
- Short-hands for Type II, Type III, and "remove this term and
  everything marginal to it" contrast tests?
  Might need to figure out the trick that car::Anova uses to do
  efficient Type II tests with two contrast matrices.

* Export information on which terms are marginal to which other ones
Marginality only makes sense within a numeric-interaction "bucket", so
this has to be computed in charlton.build and exported as part of
DesignMatrixColumnInfo.

* Some way to specify the default contrast

* Support for R's magic "." term
- The "y ~ everything else" form
- The "what I had in this other ModelDesc" form (e.g., "y ~ . - a"
  to drop the 'a' predictor from an old model)

* More stateful transforms:
- Splines
- 'cut': numeric->factor by quantile dichotimization
- Orthogonal polynomials
- 'code': takes a Categorical (or coerces to one), and optionally
  a contrast, and and does the standard contrast-coding. And
  possibly this should replace _CatFactorEvaluator...

* Support for building sparse model matrices directly. (This should
be pretty straightforward when it comes to exploiting the intrinsic
sparsity of categorical factors; numeric factors that evaluate to a
sparse matrix directly might be slightly more complicated.)


* Better NaN/masks/missing data handling in transforms. I think the
current ones will just blow up if there are any NaNs. (The previous
entry is about handling the term "x" where x has NAs; this entry is
about handling "center(x)" where x has NAs.) R's solution to this is
that scale(x) simply unconditionally ignores NAs when computing the
mean, regardless of the overall setting of na.action. That seems
reasonable...

* Real testing/support for extending the evaluation machinery with
custom operators

* A good way to support magic functions like mgcv's s().

* Ability to eliminate rows due to NaN/mask/missing data handling
(shouldn't be too bad, do it in make_design_matrices).
- And then extend make_design_matrices to handle other "parallel"
  data, like weights, which need to participate in the missingness
  calculation.

* Currently we ignore whether the levels of categorical data are
ordered. Should that change?


* Profiling/optimization. There are lots of places where I use lazy
quadratic algorithms (or even exponential, in the case of the
non-redundant coding stuff). Perhaps worse is the heavy
multiplication used unconditionally to load data into the model
matrix. I'm pretty sure that at least most of the quadratic stuff
doesn't matter because it's n^2 where n is something like the
number of factors in an interaction term (and who has hundreds of
factors interacting in one term?), but it wouldn't hurt to run some
profiles to check. I think really what I mean is just, run timeit
on a 10-variable interaction to make sure it isn't completely
annoying.

* Possible optimization: let a stateful transform's memorize_chunk
function raise Stateless to indicate that actually, ha-ha, it turns
out that it doesn't need to memorize anything after all (b/c the
relevant data turns out to be specified explicitly in *args,
**kwargs).
Actually, this would be really useful for things like splines,
which need to do expensive quantile estimation, but not if knots
are specified.
A better interface would be memorize_needed(self, *args, **kwargs).
I guess we could even have memorize_passes_needed, but eh...

* Wacky idea: make factors into an actual stateful transform (one
that takes a dict-like object and returns a matrix or Categorical)
This would require:
- adding memorize_passes support to stateful transforms
- moving the factor memorization state inside an object (so it
  wouldn't be factors that would be stateful transforms, factors would
  be factories for stateful transforms)
